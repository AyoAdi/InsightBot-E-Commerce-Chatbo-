{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvzeGp9lVGGo"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db_file_path = 'ecommerce_data.db'\n",
        "print(f\"Database will be stored temporarily at: {db_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JCeoqbtVpvE",
        "outputId": "9874c0c3-9723-4c5d-e3e3-9bffa53614ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database will be stored temporarily at: ecommerce_data.db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sqlite3.connect(db_file_path)\n",
        "cursor = conn.cursor()"
      ],
      "metadata": {
        "id": "27qVqKVbVsCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_eligibility_sql = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS product_level_eligibility_table (\n",
        "    item_id INTEGER NOT NULL,\n",
        "    eligibility_datetime_utc DATETIME NOT NULL,\n",
        "    eligibility BOOLEAN,\n",
        "    message TEXT,\n",
        "    PRIMARY KEY (item_id, eligibility_datetime_utc)\n",
        ");\n",
        "\"\"\"\n",
        "cursor.execute(create_eligibility_sql)\n",
        "print(\"Table 'product_level_eligibility_table' created or already exists.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEz3QhUIVtJj",
        "outputId": "34952d43-ee46-4f91-9425-8f80df7455b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table 'product_level_eligibility_table' created or already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_ad_sales_sql = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS product_level_ad_sales_metrics (\n",
        "    date DATE NOT NULL,\n",
        "    item_id INTEGER NOT NULL,\n",
        "    ad_sales REAL,\n",
        "    impressions INTEGER,\n",
        "    ad_spend REAL,\n",
        "    clicks INTEGER,\n",
        "    units_sold INTEGER,\n",
        "    PRIMARY KEY (date, item_id)\n",
        ");\n",
        "\"\"\"\n",
        "cursor.execute(create_ad_sales_sql)\n",
        "print(\"Table 'product_level_ad_sales_metrics' created or already exists.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv3L0avOVueE",
        "outputId": "591d682b-7c87-44c1-9037-21adb85ba935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table 'product_level_ad_sales_metrics' created or already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_total_sales_sql = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS product_level_total_sales_metrics (\n",
        "    date DATE NOT NULL,\n",
        "    item_id INTEGER NOT NULL,\n",
        "    total_sales REAL,\n",
        "    total_units_ordered INTEGER,\n",
        "    PRIMARY KEY (date, item_id)\n",
        ");\n",
        "\"\"\"\n",
        "cursor.execute(create_total_sales_sql)\n",
        "print(\"Table 'product_level_total_sales_metrics' created or already exists.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvHtOejBVv_f",
        "outputId": "df68ea05-cb59-4dd6-e654-b7fcba88c9c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table 'product_level_total_sales_metrics' created or already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conn.commit()\n",
        "print(\"All table schemas committed to the database.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_eI4-3sVxDB",
        "outputId": "13d64c7c-d876-41d1-b305-679f3ee3aa0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All table schemas committed to the database.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Define your GitHub Raw URLs ---\n",
        "eligibility_url = 'https://raw.githubusercontent.com/AyoAdi/Sales_chatbot/refs/heads/main/Datasets/Improved%20Datasets/product_level_eligibility_table_improved.csv'\n",
        "ad_sales_url = 'https://raw.githubusercontent.com/AyoAdi/Sales_chatbot/refs/heads/main/Datasets/Improved%20Datasets/product_level_sales_and_metrics_improved.csv'\n",
        "total_sales_url = 'https://raw.githubusercontent.com/AyoAdi/Sales_chatbot/refs/heads/main/Datasets/Improved%20Datasets/product_level_total_sales_and_metrics_improved.csv'\n",
        "\n",
        "print(\"Loading cleaned DataFrames from GitHub URLs...\")\n",
        "\n",
        "# 1. Load and prepare Product-Level Eligibility Table\n",
        "df_eligibility = pd.read_csv(eligibility_url)\n",
        "df_eligibility['eligibility_datetime_utc'] = pd.to_datetime(df_eligibility['eligibility_datetime_utc'])\n",
        "df_eligibility['eligibility'] = df_eligibility['eligibility'].astype(int)\n",
        "\n",
        "# 2. Load and prepare Product-Level Ad Sales and Metrics\n",
        "df_ad_sales = pd.read_csv(ad_sales_url)\n",
        "df_ad_sales['date'] = pd.to_datetime(df_ad_sales['date'])\n",
        "\n",
        "# 3. Load and prepare Product-Level Total Sales and Metrics\n",
        "df_total_sales = pd.read_csv(total_sales_url)\n",
        "df_total_sales['date'] = pd.to_datetime(df_total_sales['date'])\n",
        "\n",
        "print(\"DataFrames loaded and prepped.\")\n",
        "print(\"Loading data into SQL tables...\")\n",
        "\n",
        "# --- FIX: Change 'if_exists' to 'replace' for initial load/testing ---\n",
        "# This will drop the table if it exists and recreate it before inserting.\n",
        "df_eligibility.to_sql(\n",
        "    'product_level_eligibility_table',\n",
        "    conn,\n",
        "    if_exists='replace', # Changed from 'append' to 'replace'\n",
        "    index=False\n",
        ")\n",
        "print(\"Data loaded into 'product_level_eligibility_table'.\")\n",
        "\n",
        "df_ad_sales.to_sql(\n",
        "    'product_level_ad_sales_metrics',\n",
        "    conn,\n",
        "    if_exists='replace', # Changed from 'append' to 'replace'\n",
        "    index=False\n",
        ")\n",
        "print(\"Data loaded into 'product_level_ad_sales_metrics'.\")\n",
        "\n",
        "df_total_sales.to_sql(\n",
        "    'product_level_total_sales_metrics',\n",
        "    conn,\n",
        "    if_exists='replace', # Changed from 'append' to 'replace'\n",
        "    index=False\n",
        ")\n",
        "print(\"Data loaded into 'product_level_total_sales_metrics'.\")\n",
        "\n",
        "conn.commit()\n",
        "print(\"All data committed to the database.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbcBBtZLVzBY",
        "outputId": "6d7f927c-58ff-4143-906c-01d68b7c12e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading cleaned DataFrames from GitHub URLs...\n",
            "DataFrames loaded and prepped.\n",
            "Loading data into SQL tables...\n",
            "Data loaded into 'product_level_eligibility_table'.\n",
            "Data loaded into 'product_level_ad_sales_metrics'.\n",
            "Data loaded into 'product_level_total_sales_metrics'.\n",
            "All data committed to the database.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The tables are now created!! So the next step is to pick an LLM or an api key to handle the entire process"
      ],
      "metadata": {
        "id": "HuFPmGzEV03X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYhlOW7qV17u",
        "outputId": "ebdf3ba2-6d96-45e6-9169-b3c9d0ababd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.176.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import google.generativeai as genai\n",
        "print(\"Libraries installed and imported.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiyGaftLV8Yx",
        "outputId": "191f1264-5ef6-4318-a718-a2da51811716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries installed and imported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db_file_path = 'ecommerce_data.db'\n",
        "print(f\"Database will be stored temporarily at: {db_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJkLKPHdaowZ",
        "outputId": "c2970a12-b33e-4b86-a0d8-8f159e2766ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database will be stored temporarily at: ecommerce_data.db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qApuaSM-czfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sqlite3.connect(db_file_path)\n",
        "cursor = conn.cursor()\n",
        "print(\"Connected to SQLite database.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OftyWuUiWD8P",
        "outputId": "2d59686e-498a-42c2-acb4-d38c05f01374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to SQLite database.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nConfiguring Gemini Pro LLM...\")\n",
        "# Get API key from Colab Secrets\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    # This correctly references the secret named 'GOOGLE_API_KEY'\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\"Gemini API key loaded from Colab Secrets and configured.\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: Could not load Gemini API key from Colab Secrets. Please check secret name and access: {e}\")\n",
        "    print(\"Ensure your Gemini API key is stored as a Colab Secret named 'GOOGLE_API_KEY' and notebook access is enabled.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt0LqSljXTra",
        "outputId": "1e6424a3-3391-4663-aa3c-717b3c2bfa97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Configuring Gemini Pro LLM...\n",
            "Gemini API key loaded from Colab Secrets and configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_model = genai.GenerativeModel('models/gemini-2.0-flash')\n",
        "print(\"Gemini Flash model initialized.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mhsodrd7XiME",
        "outputId": "184c2da4-0b2e-418e-dfac-0f2daca38b2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Flash model initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_table_schema(cursor):\n",
        "    \"\"\"Fetches the schema of all tables in the SQLite database.\"\"\"\n",
        "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "    tables = cursor.fetchall()\n",
        "    schema_info = {}\n",
        "    for table_name_tuple in tables:\n",
        "        table_name = table_name_tuple[0]\n",
        "        cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
        "        columns = cursor.fetchall()\n",
        "        column_details = []\n",
        "        for col in columns:\n",
        "            cid, name, ctype, notnull, dflt_value, pk = col\n",
        "            column_details.append(f\"{name} {ctype} {'NOT NULL' if notnull else ''} {'PRIMARY KEY' if pk else ''}\")\n",
        "        schema_info[table_name] = \", \".join(column_details)\n",
        "    return schema_info"
      ],
      "metadata": {
        "id": "BYTEvceCXk1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_llm_for_sql(question: str, schema: dict, gemini_model) -> str:\n",
        "    \"\"\"\n",
        "    Asks the Gemini Pro LLM to convert a natural language question into an SQL query.\n",
        "    \"\"\"\n",
        "    schema_str = \"\\n\".join([f\"Table: {table}\\nColumns: {cols}\" for table, cols in schema.items()])\n",
        "\n",
        "    prompt_parts = [\n",
        "        \"You are an expert SQL query generator. Your sole purpose is to convert user questions into precise and accurate SQL queries.\",\n",
        "        \"You must use the provided database schema to identify the correct tables and columns.\",\n",
        "        \"Strictly adhere to the schema provided below.\",\n",
        "        \"\",\n",
        "        \"Here is the database schema:\",\n",
        "        schema_str,\n",
        "        \"\",\n",
        "        \"**Important Rules for SQL Generation:**\",\n",
        "        \"-   **Always select the correct table(s) based on the question's context.**\",\n",
        "        \"    -   'total sales', 'units ordered' -> use `product_level_total_sales_metrics`\",\n",
        "        \"    -   'ad sales', 'impressions', 'ad spend', 'clicks', 'units sold from ads', 'CPC', 'RoAS' -> use `product_level_ad_sales_metrics`\",\n",
        "        \"    -   'eligible products', 'eligibility status' -> use `product_level_eligibility_table`\",\n",
        "        \"-   Use appropriate SQL aggregate functions (SUM, AVG, MAX, MIN, COUNT) for questions involving totals, averages, highest/lowest, or counts.\",\n",
        "        \"-   Use JOINs only when necessary to combine data from different tables based on common columns (like item_id or date).\",\n",
        "        \"-   Filter data using WHERE clauses (e.g., for specific dates, item_ids, or eligibility status).\",\n",
        "        \"-   When asked for 'Which product...' or 'Top X products...', use `GROUP BY item_id` with `ORDER BY` and `LIMIT`.\",\n",
        "        \"-   Ensure column names and table names exactly match the schema.\",\n",
        "        \"-   For RoAS, use `SUM(ad_sales) * 1.0 / SUM(ad_spend)` to ensure float division.\",\n",
        "        \"-   For CPC, use `SUM(ad_spend) * 1.0 / SUM(clicks)` to ensure float division.\",\n",
        "        \"-   **Output Format: STRICTLY ONLY THE SQL QUERY. DO NOT include any markdown code blocks (e.g., ```sql ```), introductory text, explanations, or concluding remarks.**\",\n",
        "        \"\",\n",
        "        \"Examples:\",\n",
        "        \"User Question: What is my total sales?\",\n",
        "        \"SQL Query: SELECT SUM(total_sales) FROM product_level_total_sales_metrics;\",\n",
        "        \"\",\n",
        "        \"User Question: Calculate the RoAS (Return on Ad Spend).\",\n",
        "        \"SQL Query: SELECT SUM(ad_sales) * 1.0 / SUM(ad_spend) FROM product_level_ad_sales_metrics;\",\n",
        "        \"\",\n",
        "        \"User Question: Which product had the highest CPC (Cost Per Click)?\",\n",
        "        \"SQL Query: SELECT item_id, SUM(ad_spend) * 1.0 / SUM(clicks) AS cpc FROM product_level_ad_sales_metrics GROUP BY item_id ORDER BY cpc DESC LIMIT 1;\",\n",
        "        \"\",\n",
        "        \"User Question: How many eligible products are there?\",\n",
        "        \"SQL Query: SELECT COUNT(DISTINCT item_id) FROM product_level_eligibility_table WHERE eligibility = 1;\",\n",
        "        \"\",\n",
        "        \"User Question: What was the total units ordered on 2023-01-01?\",\n",
        "        \"SQL Query: SELECT SUM(total_units_ordered) FROM product_level_total_sales_metrics WHERE date = '2023-01-01';\",\n",
        "        \"\",\n",
        "        \"User Question: Show me the ad sales for item 12345 on 2023-01-05.\",\n",
        "        \"SQL Query: SELECT ad_sales FROM product_level_ad_sales_metrics WHERE item_id = 12345 AND date = '2023-01-05';\",\n",
        "        \"\",\n",
        "        f\"User Question: {question}\",\n",
        "        \"SQL Query:\"\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        response = genai.GenerativeModel.generate_content(gemini_model, \"\\n\".join(prompt_parts))\n",
        "        generated_text = response.text.strip()\n",
        "\n",
        "        # Refined parsing logic (same as before, it's good to keep this for robustness)\n",
        "        if generated_text.lower().startswith(\"```sql\"):\n",
        "            generated_text = generated_text[len(\"```sql\"):].strip()\n",
        "        if generated_text.endswith(\"```\"):\n",
        "            generated_text = generated_text[:-len(\"```\")].strip()\n",
        "        if generated_text.startswith(\"```\"):\n",
        "            generated_text = generated_text[len(\"```\"):].strip()\n",
        "\n",
        "        sql_lines = generated_text.split('\\n')\n",
        "        final_sql = []\n",
        "        in_sql_block = False\n",
        "        for line in sql_lines:\n",
        "            stripped_line_upper = line.strip().upper()\n",
        "            if not in_sql_block and any(stripped_line_upper.startswith(kw) for kw in [\"SELECT\", \"INSERT\", \"UPDATE\", \"DELETE\", \"CREATE\", \"DROP\", \"ALTER\", \"WITH\", \"PRAGMA\"]):\n",
        "                in_sql_block = True\n",
        "                final_sql.append(line)\n",
        "            elif in_sql_block:\n",
        "                if stripped_line_upper == \"\" or (not any(char.isalpha() for char in stripped_line_upper) and ';' not in stripped_line_upper):\n",
        "                    break\n",
        "                final_sql.append(line)\n",
        "\n",
        "        sql_query = \"\\n\".join(final_sql).strip()\n",
        "\n",
        "        if sql_query and not sql_query.endswith(';'):\n",
        "            last_word = sql_query.split()[-1].upper() if sql_query.split() else \"\"\n",
        "            if not any(last_word.endswith(kw) for kw in [\"FROM\", \"WHERE\", \"BY\", \"LIMIT\", \"ON\"]):\n",
        "                 sql_query += ';'\n",
        "\n",
        "        return sql_query\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating or parsing SQL from Gemini: {e}\")\n",
        "        return \"ERROR: Failed to generate or parse SQL query from LLM.\""
      ],
      "metadata": {
        "id": "2ajjFHuYXolO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_sql_query(cursor, sql_query):\n",
        "    \"\"\"Executes an SQL query and returns the results.\"\"\"\n",
        "    try:\n",
        "        cursor.execute(sql_query)\n",
        "        result = cursor.fetchall()\n",
        "        column_names = [description[0] for description in cursor.description] if cursor.description else []\n",
        "        return result, column_names\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"SQL Error: {e}\")\n",
        "        return None, None\n"
      ],
      "metadata": {
        "id": "XopNskBbXqkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_answer(question: str, result: list, column_names: list) -> str:\n",
        "    \"\"\"\n",
        "    Formats the SQL query result into a human-readable string.\n",
        "    \"\"\"\n",
        "    if result is None:\n",
        "        return \"I encountered an error while querying the database.\"\n",
        "    if not result:\n",
        "        return \"I couldn't find any relevant data for that question.\"\n",
        "\n",
        "    if len(result) == 1 and len(result[0]) == 1:\n",
        "        value = result[0][0]\n",
        "        if isinstance(value, (int, float)):\n",
        "            return f\"The {question.lower()} is: {value:,.2f}\" if 'sales' in question.lower() or 'spend' in question.lower() else f\"The {question.lower()} is: {value}\"\n",
        "        else:\n",
        "            return f\"The answer to '{question}' is: {value}\"\n",
        "    else:\n",
        "        df_result = pd.DataFrame(result, columns=column_names)\n",
        "        return f\"Here is the data for '{question}':\\n{df_result.to_string(index=False)}\""
      ],
      "metadata": {
        "id": "6IuQ0y3zXsgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main AI Agent Function\n",
        "def ask_ai_agent(question: str, gemini_model, cursor) -> str:\n",
        "    \"\"\"\n",
        "    Orchestrates the AI agent's process to answer a question.\n",
        "    \"\"\"\n",
        "    print(f\"\\nUser: {question}\")\n",
        "    print(\"Fetching schema...\")\n",
        "    schema = get_table_schema(cursor)\n",
        "    print(\"Schema fetched.\")\n",
        "\n",
        "    print(\"Asking LLM for SQL query...\")\n",
        "    sql_query = ask_llm_for_sql(question, schema, gemini_model)\n",
        "    print(f\"Generated SQL: {sql_query}\")\n",
        "\n",
        "    if sql_query.startswith(\"ERROR:\"):\n",
        "        return sql_query\n",
        "\n",
        "    print(\"Executing SQL query...\")\n",
        "    query_result, column_names = execute_sql_query(cursor, sql_query)\n",
        "    print(\"SQL query executed.\")\n",
        "\n",
        "    print(\"Formatting answer...\")\n",
        "    human_readable_answer = format_answer(question, query_result, column_names)\n",
        "    print(\"Answer formatted.\")\n",
        "\n",
        "    return human_readable_answer"
      ],
      "metadata": {
        "id": "ziCOur1AXvHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile run_agent.py\n",
        "# run_agent.py - This script runs your AI agent from the Colab Terminal\n",
        "\n",
        "# --- Phase 0: Initial Setup and Imports ---\n",
        "# These packages need to be installed in the terminal's environment.\n",
        "# We'll use subprocess to ensure they are installed when the script runs.\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_packages():\n",
        "    print(\"Installing/Upgrading necessary Python packages...\")\n",
        "    try:\n",
        "        # Use sys.executable to ensure pip is called from the correct Python environment\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"google-generativeai\", \"pandas\"])\n",
        "        print(\"Packages installed successfully.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error installing packages: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "install_packages() # Run installation when the script starts\n",
        "\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import time\n",
        "\n",
        "print(\"Libraries imported.\")\n",
        "\n",
        "# --- Phase 1: Database Setup and Connection ---\n",
        "\n",
        "# Define Database File Path (Temporary Storage - will be deleted when session ends)\n",
        "db_file_path = 'ecommerce_data.db'\n",
        "print(f\"Database will be stored temporarily at: {db_file_path}\")\n",
        "\n",
        "# Connect to the SQLite database file\n",
        "conn = sqlite3.connect(db_file_path)\n",
        "cursor = conn.cursor()\n",
        "print(\"Connected to SQLite database.\")\n",
        "\n",
        "\n",
        "# --- Phase 2: Define and Create SQL Tables ---\n",
        "create_eligibility_sql = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS product_level_eligibility_table (\n",
        "    item_id INTEGER NOT NULL,\n",
        "    eligibility_datetime_utc DATETIME NOT NULL,\n",
        "    eligibility BOOLEAN,\n",
        "    message TEXT,\n",
        "    PRIMARY KEY (item_id, eligibility_datetime_utc)\n",
        ");\n",
        "\"\"\"\n",
        "cursor.execute(create_eligibility_sql)\n",
        "print(\"Table 'product_level_eligibility_table' created or already exists.\")\n",
        "\n",
        "create_ad_sales_sql = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS product_level_ad_sales_metrics (\n",
        "    date DATE NOT NULL,\n",
        "    item_id INTEGER NOT NULL,\n",
        "    ad_sales REAL,\n",
        "    impressions INTEGER,\n",
        "    ad_spend REAL,\n",
        "    clicks INTEGER,\n",
        "    units_sold INTEGER,\n",
        "    PRIMARY KEY (date, item_id)\n",
        ");\n",
        "\"\"\"\n",
        "cursor.execute(create_ad_sales_sql)\n",
        "print(\"Table 'product_level_ad_sales_metrics' created or already exists.\")\n",
        "\n",
        "create_total_sales_sql = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS product_level_total_sales_metrics (\n",
        "    date DATE NOT NULL,\n",
        "    item_id INTEGER NOT NULL,\n",
        "    total_sales REAL,\n",
        "    total_units_ordered INTEGER,\n",
        "    PRIMARY KEY (date, item_id)\n",
        ");\n",
        "\"\"\"\n",
        "cursor.execute(create_total_sales_sql)\n",
        "print(\"Table 'product_level_total_sales_metrics' created or already exists.\")\n",
        "\n",
        "conn.commit()\n",
        "print(\"All table schemas committed to the database.\")\n",
        "\n",
        "\n",
        "# --- Phase 3: Load Data from GitHub URLs into SQL Tables ---\n",
        "eligibility_url = 'https://raw.githubusercontent.com/AyoAdi/Sales_chatbot/refs/heads/main/Datasets/Improved%20Datasets/product_level_eligibility_table_improved.csv'\n",
        "ad_sales_url = 'https://raw.githubusercontent.com/AyoAdi/Sales_chatbot/refs/heads/main/Datasets/Improved%20Datasets/product_level_sales_and_metrics_improved.csv'\n",
        "total_sales_url = 'https://raw.githubusercontent.com/AyoAdi/Sales_chatbot/refs/heads/main/Datasets/Improved%20Datasets/product_level_total_sales_and_metrics_improved.csv'\n",
        "\n",
        "print(\"\\nLoading cleaned DataFrames from GitHub URLs...\")\n",
        "\n",
        "df_eligibility = pd.read_csv(eligibility_url)\n",
        "df_eligibility['eligibility_datetime_utc'] = pd.to_datetime(df_eligibility['eligibility_datetime_utc'])\n",
        "df_eligibility['eligibility'] = df_eligibility['eligibility'].astype(int)\n",
        "\n",
        "df_ad_sales = pd.read_csv(ad_sales_url)\n",
        "df_ad_sales['date'] = pd.to_datetime(df_ad_sales['date'])\n",
        "\n",
        "df_total_sales = pd.read_csv(total_sales_url)\n",
        "df_total_sales['date'] = pd.to_datetime(df_total_sales['date'])\n",
        "\n",
        "print(\"DataFrames loaded and prepped.\")\n",
        "print(\"Loading data into SQL tables...\")\n",
        "\n",
        "df_eligibility.to_sql( 'product_level_eligibility_table', conn, if_exists='replace', index=False)\n",
        "print(\"Data loaded into 'product_level_eligibility_table'.\")\n",
        "\n",
        "df_ad_sales.to_sql( 'product_level_ad_sales_metrics', conn, if_exists='replace', index=False)\n",
        "print(\"Data loaded into 'product_level_ad_sales_metrics'.\")\n",
        "\n",
        "df_total_sales.to_sql( 'product_level_total_sales_metrics', conn, if_exists='replace', index=False)\n",
        "print(\"Data loaded into 'product_level_total_sales_metrics'.\")\n",
        "\n",
        "conn.commit()\n",
        "print(\"All data committed to the database.\")\n",
        "\n",
        "\n",
        "# --- Phase 4: Configure and Use Gemini Flash LLM ---\n",
        "\n",
        "print(\"\\nConfiguring Gemini Flash LLM...\")\n",
        "# CORRECTED: Use os.getenv() to read API key from environment variable\n",
        "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
        "if GOOGLE_API_KEY:\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\"Gemini API key loaded from environment variable and configured.\")\n",
        "else:\n",
        "    print(\"ERROR: GOOGLE_API_KEY environment variable not found.\")\n",
        "    print(\"Please set the GOOGLE_API_KEY environment variable in the terminal before running this script.\")\n",
        "    sys.exit(1) # Exit if API key is not found\n",
        "\n",
        "# Initialize the Gemini Flash model\n",
        "gemini_model = genai.GenerativeModel('models/gemini-2.5-flash')\n",
        "print(\"Gemini Flash model initialized.\")\n",
        "\n",
        "\n",
        "# --- Phase 5: AI Agent Core Logic Functions ---\n",
        "\n",
        "def get_table_schema(cursor):\n",
        "    \"\"\"Fetches the schema of all tables in the SQLite database.\"\"\"\n",
        "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "    tables = cursor.fetchall()\n",
        "    schema_info = {}\n",
        "    for table_name_tuple in tables:\n",
        "        table_name = table_name_tuple[0]\n",
        "        cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
        "        columns = cursor.fetchall()\n",
        "        column_details = []\n",
        "        for col in columns:\n",
        "            cid, name, ctype, notnull, dflt_value, pk = col\n",
        "            column_details.append(f\"{name} {ctype} {'NOT NULL' if notnull else ''} {'PRIMARY KEY' if pk else ''}\")\n",
        "        schema_info[table_name] = \", \".join(column_details)\n",
        "    return schema_info\n",
        "\n",
        "\n",
        "def ask_llm_for_sql(question: str, schema: dict, gemini_model) -> str:\n",
        "    \"\"\"\n",
        "    Asks the Gemini LLM to convert a natural language question into an SQL query.\n",
        "    Returns the full generated SQL query string.\n",
        "    \"\"\"\n",
        "    schema_str = \"\\n\".join([f\"Table: {table}\\nColumns: {cols}\" for table, cols in schema.items()])\n",
        "\n",
        "    prompt_parts = [\n",
        "        \"You are an expert SQL query generator. Your sole purpose is to convert user questions into precise and accurate SQL queries.\",\n",
        "        \"You must use the provided database schema to identify the correct tables and columns.\",\n",
        "        \"Strictly adhere to the schema provided below.\",\n",
        "        \"\",\n",
        "        \"Here is the database schema:\",\n",
        "        schema_str,\n",
        "        \"\",\n",
        "        \"**Important Rules for SQL Generation:**\",\n",
        "        \"-   **Always select the correct table(s) based on the question's context.**\",\n",
        "        \"    -   'total sales', 'units ordered' -> use `product_level_total_sales_metrics`\",\n",
        "        \"    -   'ad sales', 'impressions', 'ad spend', 'clicks', 'units sold from ads', 'CPC', 'RoAS' -> use `product_level_ad_sales_metrics`\",\n",
        "        \"    -   'eligible products', 'eligibility status' -> use `product_level_eligibility_table`\",\n",
        "        \"-   Use appropriate SQL aggregate functions (SUM, AVG, MAX, MIN, COUNT) for questions involving totals, averages, highest/lowest, or counts.\",\n",
        "        \"-   Use JOINs only when necessary to combine data from different tables based on common columns (like item_id or date).\",\n",
        "        \"-   Filter data using WHERE clauses (e.g., for specific dates, item_ids, or eligibility status).\",\n",
        "        \"-   When asked for 'Which product...' or 'Top X products...', use `GROUP BY item_id` with `ORDER BY` and `LIMIT`.\",\n",
        "        \"-   Ensure column names and table names exactly match the schema.\",\n",
        "        \"-   For RoAS, use `SUM(ad_sales) * 1.0 / SUM(ad_spend)` to ensure float division.\",\n",
        "        \"-   For CPC, use `SUM(ad_spend) * 1.0 / SUM(clicks)` to ensure float division.\",\n",
        "        \"-   **Output Format: STRICTLY ONLY THE SQL QUERY. DO NOT include any markdown code blocks (e.g., ```sql ```), introductory text, explanations, or concluding remarks.**\",\n",
        "        \"\",\n",
        "        \"Examples:\",\n",
        "        \"User Question: What is my total sales?\",\n",
        "        \"SQL Query: SELECT SUM(total_sales) FROM product_level_total_sales_metrics;\",\n",
        "        \"\",\n",
        "        \"User Question: Calculate the RoAS (Return on Ad Spend).\",\n",
        "        \"SQL Query: SELECT SUM(ad_sales) * 1.0 / SUM(ad_spend) FROM product_level_ad_sales_metrics;\",\n",
        "        \"\",\n",
        "        \"User Question: Which product had the highest CPC (Cost Per Click)?\",\n",
        "        \"SQL Query: SELECT item_id, SUM(ad_spend) * 1.0 / SUM(clicks) AS cpc FROM product_level_ad_sales_metrics GROUP BY item_id ORDER BY cpc DESC LIMIT 1;\",\n",
        "        \"\",\n",
        "        f\"User Question: {question}\",\n",
        "        \"SQL Query:\"\n",
        "    ]\n",
        "\n",
        "    full_generated_sql_text = \"\"\n",
        "    try:\n",
        "        response = gemini_model.generate_content(\"\\n\".join(prompt_parts))\n",
        "        full_generated_sql_text = response.text.strip()\n",
        "\n",
        "        generated_text = full_generated_sql_text.strip()\n",
        "\n",
        "        if generated_text.lower().startswith(\"```sql\"):\n",
        "            generated_text = generated_text[len(\"```sql\"):].strip()\n",
        "        if generated_text.endswith(\"```\"):\n",
        "            generated_text = generated_text[:-len(\"```\")].strip()\n",
        "        if generated_text.startswith(\"```\"):\n",
        "            generated_text = generated_text[len(\"```\"):].strip()\n",
        "\n",
        "        sql_lines = generated_text.split('\\n')\n",
        "        final_sql = []\n",
        "        in_sql_block = False\n",
        "        for line in sql_lines:\n",
        "            stripped_line_upper = line.strip().upper()\n",
        "            if not in_sql_block and any(stripped_line_upper.startswith(kw) for kw in [\"SELECT\", \"INSERT\", \"UPDATE\", \"DELETE\", \"CREATE\", \"DROP\", \"ALTER\", \"WITH\", \"PRAGMA\"]):\n",
        "                in_sql_block = True\n",
        "                final_sql.append(line)\n",
        "            elif in_sql_block:\n",
        "                if stripped_line_upper == \"\" or (not any(char.isalpha() for char in stripped_line_upper) and ';' not in stripped_line_upper):\n",
        "                    break\n",
        "                final_sql.append(line)\n",
        "\n",
        "        sql_query = \"\\n\".join(final_sql).strip()\n",
        "\n",
        "        if sql_query and not sql_query.endswith(';'):\n",
        "            last_word = sql_query.split()[-1].upper() if sql_query.split() else \"\"\n",
        "            if not any(last_word.endswith(kw) for kw in [\"FROM\", \"WHERE\", \"BY\", \"LIMIT\", \"ON\"]):\n",
        "                 sql_query += ';'\n",
        "\n",
        "        return sql_query\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating or parsing SQL from Gemini: {e}\")\n",
        "        return \"ERROR: Failed to generate or parse SQL query from LLM.\"\n",
        "\n",
        "\n",
        "def execute_sql_query(cursor, sql_query):\n",
        "    \"\"\"Executes an SQL query and returns the results.\"\"\"\n",
        "    try:\n",
        "        cursor.execute(sql_query)\n",
        "        result = cursor.fetchall()\n",
        "        column_names = [description[0] for description in cursor.description] if cursor.description else []\n",
        "        return result, column_names\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"SQL Error: {e}\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "def format_answer(question: str, result: list, column_names: list) -> str:\n",
        "    \"\"\"\n",
        "    Formats the SQL query result into a human-readable string.\n",
        "    \"\"\"\n",
        "    if result is None:\n",
        "        return \"I encountered an error while querying the database.\"\n",
        "    if not result:\n",
        "        return \"I couldn't find any relevant data for that question.\"\n",
        "\n",
        "    if len(result) == 1 and len(result[0]) == 1:\n",
        "        value = result[0][0]\n",
        "        if isinstance(value, (int, float)):\n",
        "            return f\"The {question.lower()} is: {value:,.2f}\" if 'sales' in question.lower() or 'spend' in question.lower() else f\"The {question.lower()} is: {value}\"\n",
        "        else:\n",
        "            return f\"The answer to '{question}' is: {value}\"\n",
        "    else:\n",
        "        df_result = pd.DataFrame(result, columns=column_names)\n",
        "        return f\"Here is the data for '{question}':\\n{df_result.to_string(index=False)}\"\n",
        "\n",
        "\n",
        "# --- Main AI Agent Function (for command-line interaction) ---\n",
        "def ask_ai_agent_cli(question: str, gemini_model, cursor) -> str:\n",
        "    \"\"\"\n",
        "    Orchestrates the AI agent's process to answer a question for CLI.\n",
        "    \"\"\"\n",
        "    print(f\"\\nUser: {question}\")\n",
        "    print(\"Fetching schema...\")\n",
        "    schema = get_table_schema(cursor)\n",
        "    print(\"Schema fetched.\")\n",
        "\n",
        "    print(\"Asking LLM for SQL query...\")\n",
        "    sql_query = ask_llm_for_sql(question, schema, gemini_model)\n",
        "    print(f\"Generated SQL: {sql_query}\")\n",
        "\n",
        "    if sql_query.startswith(\"ERROR:\"):\n",
        "        return sql_query\n",
        "\n",
        "    print(\"Executing SQL query...\")\n",
        "    query_result, column_names = execute_sql_query(cursor, sql_query)\n",
        "    print(\"SQL query executed.\")\n",
        "\n",
        "    print(\"Formatting answer...\")\n",
        "    human_readable_answer = format_answer(question, query_result, column_names)\n",
        "    print(\"Answer formatted.\")\n",
        "\n",
        "    return human_readable_answer\n",
        "\n",
        "\n",
        "# --- Interactive Command-Line Interface Loop (Entry Point) ---\n",
        "if __name__ == \"__main__\": # This ensures the code below only runs when the script is executed directly\n",
        "    # Get the schema once\n",
        "    db_schema = get_table_schema(cursor)\n",
        "    print(\"\\n--- Database Schema ---\")\n",
        "    for table, cols in db_schema.items():\n",
        "        print(f\"{table}: {cols}\")\n",
        "    print(\"---------------------\\n\")\n",
        "\n",
        "    print(\"--- AI Agent Command-Line Interface ---\")\n",
        "    print(\"Type your questions and press Enter. Type 'exit' to quit.\")\n",
        "    print(\"Examples: 'What is my total sales?', 'Calculate the RoAS (Return on Ad Spend).'\")\n",
        "    print(\"---------------------------------------\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_question = input(\"You: \")\n",
        "        if user_question.lower().strip() == 'exit':\n",
        "            print(\"AI: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        answer = ask_ai_agent_cli(user_question, gemini_model, cursor)\n",
        "        print(f\"AI: {answer}\\n\")\n",
        "\n",
        "    # Close the database connection when the loop exits\n",
        "    conn.close()\n",
        "    print(\"Database connection closed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kONq4CFj0pV1",
        "outputId": "e5df41a5-9384-4795-c1d2-26d947169113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing run_agent.py\n"
          ]
        }
      ]
    }
  ]
}